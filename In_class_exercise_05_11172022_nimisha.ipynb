{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/17/2022)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a stirring , funny and finally transporting r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>apparently reassembled from the cutting-room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>they presume their audience wo n't sit still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a visually stunning rumination on lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>jonathan parker 's bartleby should have been ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reviews                                               Text\n",
       "0       1   a stirring , funny and finally transporting r...\n",
       "1       0   apparently reassembled from the cutting-room ...\n",
       "2       0   they presume their audience wo n't sit still ...\n",
       "3       1   this is a visually stunning rumination on lov...\n",
       "4       1   jonathan parker 's bartleby should have been ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"stsa-train.txt\") as txtf:\n",
    "    mylist = [line.rstrip('\\n') for line in txtf]\n",
    "    \n",
    "labels = []\n",
    "text = []\n",
    "\n",
    "for i, line in enumerate(mylist):\n",
    "    label = mylist[i][0]\n",
    "    tex = mylist[i][1:]\n",
    "    labels.append(label)\n",
    "    text.append(tex)\n",
    "\n",
    "dataset = pd.DataFrame(list(zip(labels, text)),columns =['Reviews', 'Text'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "dataset['cleanText']=dataset['Text'].map(lambda s:preprocess(s)) \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stsa-test.txt\") as txtf:\n",
    "    mylist_test = [line.rstrip('\\n') for line in txtf]\n",
    "    \n",
    "labels_test = []\n",
    "text_test = []\n",
    "\n",
    "for i, line in enumerate(mylist_test):\n",
    "    label_test = mylist_test[i][0]\n",
    "    tex_test = mylist_test[i][1:]\n",
    "    labels_test.append(label_test)\n",
    "    text_test.append(tex_test)\n",
    "\n",
    "dataset_test = pd.DataFrame(list(zip(labels_test, text_test)),columns =['Reviews', 'Text'])\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "dataset_test['cleanText']=dataset_test['Text'].map(lambda s:preprocess(s)) \n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase = False, analyzer='word')\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(dataset[\"cleanText\"]).toarray()\n",
    "test_tfidf = tfidf_vectorizer.transform(dataset_test[\"cleanText\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_tfidf\n",
    "y_test = dataset_test[\"Reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_tfidf,dataset[\"Reviews\"],test_size = 0.2, random_state = 202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(x_train, y_train) \n",
    "predictions_validation_set = classifier.predict(x_valid) \n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print (\"Accuracy of the Naive Bayes model on validation set is : \", round(accuracy_score(y_valid, predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_naive_validation = classification_report(y_valid, predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "naive_accuracies_validation = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"Naive Bayes Model  10-fold cross validation score on training set is :  {round(naive_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_set = classifier.predict(x_test) \n",
    "print (\"Accuracy of the Naive Bayes model on test set is : \", round(accuracy_score(y_test, predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_naive_test = classification_report(y_test, predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_accuracies_test = cross_val_score(estimator = classifier, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"Naive Bayes Model 10-fold cross validation score on testing set is :  {round(naive_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier_svm = svm.SVC()\n",
    "model_svm = classifier_svm.fit(x_train, y_train) \n",
    "svm_predictions_validation_set = classifier_svm.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the SVM model on validation set is : \", round(accuracy_score(y_valid, svm_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_svm_validation = classification_report(y_valid, svm_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "svm_accuracies_validation = cross_val_score(estimator = classifier_svm, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"SVM Model  10-fold cross validation score on training set is :  {round(svm_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions_test_set = classifier_svm.predict(x_test) \n",
    "print (\"Accuracy of the SVM model on test set is : \", round(accuracy_score(y_test, svm_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_svm_test = classification_report(y_test, svm_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracies_test = cross_val_score(estimator = classifier_svm, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"SVM Model 10-fold cross validation score on testing set is :  {round(svm_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "model_knn = classifier_knn.fit(x_train, y_train) \n",
    "knn_predictions_validation_set = classifier_knn.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the KNN model on validation set is : \", round(accuracy_score(y_valid, knn_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn_accuracies_validation = cross_val_score(estimator = classifier_knn, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"KNN Model  10-fold cross validation score on training set is :  {round(knn_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions_test_set = classifier_knn.predict(x_test) \n",
    "print (\"Accuracy of the KNN model on test set is : \", round(accuracy_score(y_test, knn_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_knn_test = classification_report(y_test, knn_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies_test = cross_val_score(estimator = classifier_knn, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"KNN Model 10-fold cross validation score on testing set is :  {round(knn_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "model_dt = classifier_dt.fit(x_train, y_train) \n",
    "dt_predictions_validation_set = classifier_dt.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the Decison Tree Classifier model on validation set is : \", round(accuracy_score(y_valid, dt_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_valid, dt_predictions_validation_set, pos_label='0')*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_dt_validation = classification_report(y_valid, dt_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dt_accuracies_validation = cross_val_score(estimator = classifier_dt, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"Decison Tree Classifier Model  10-fold cross validation score on training set is :  {round(dt_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions_test_set = classifier_dt.predict(x_test) \n",
    "print (\"Accuracy of the Decison Tree Classifier model on test set is : \", round(accuracy_score(y_test, dt_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_dt_test = classification_report(y_test, dt_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_accuracies_test = cross_val_score(estimator = classifier_dt, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"Decison Tree Classifier Model 10-fold cross validation score on testing set is :  {round(dt_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_rf = RandomForestClassifier()\n",
    "model_rf = classifier_rf.fit(x_train, y_train) \n",
    "rf_predictions_validation_set = classifier_rf.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the Random Forest Classifier model on validation set is : \", round(accuracy_score(y_valid, rf_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_valid, rf_predictions_validation_set, pos_label='0')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_rf_validation = classification_report(y_valid, rf_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf_accuracies_validation = cross_val_score(estimator = classifier_rf, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"Decison Random Forest Model  10-fold cross validation score on training set is :  {round(rf_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_test_set = classifier_rf.predict(x_test) \n",
    "print (\"Accuracy of the Random Forest Classifier model on test set is : \", round(accuracy_score(y_test, rf_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_rf_test = classification_report(y_test, rf_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracies_test = cross_val_score(estimator = classifier_rf, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"Random Forest Classifier Model 10-fold cross validation score on testing set is :  {round(rf_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifier_xgb = XGBClassifier()\n",
    "model_xgb = classifier_xgb.fit(x_train, y_train) \n",
    "xgb_predictions_validation_set = classifier_xgb.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the XGBoost Classifier model on validation set is : \", round(accuracy_score(y_valid, xgb_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_valid, xgb_predictions_validation_set, pos_label='0')*100),\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_xgb_validation = classification_report(y_valid, xgb_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "xgb_accuracies_validation = cross_val_score(estimator = classifier_xgb, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"XGBoost Model  10-fold cross validation score on training set is :  {round(xgb_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions_test_set = classifier_xgb.predict(x_test) \n",
    "print (\"Accuracy of the XGBoost Classifier model on test set is : \", round(accuracy_score(y_test, xgb_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_xgb_test = classification_report(y_test, xgb_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_accuracies_test = cross_val_score(estimator = classifier_xgb, X = x_test, y = y_test, cv = 10)\n",
    "\n",
    "print(f\"XGBoost Classifier Model 10-fold cross validation score on testing set is :  {round(xgb_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here.\n",
    "\n",
    "df = pd.read_csv('Amazon_Unlocked_Mobile1.csv')\n",
    "\n",
    "df['Reviews']=df['Reviews'].map(lambda s:preprocess(s)) \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZATION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
    "names= tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ELBOW METHOD\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(2,12):\n",
    "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", random_state = 101)\n",
    "    kmeans.fit(tfidf_vects)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize = (11,6))\n",
    "plt.plot(range(2,12), wcss, marker = \"o\")\n",
    "plt.title (\"The Elbow Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming 6 clusters\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 6,init='k-means++',max_iter=10000, random_state=50)\n",
    "model.fit(tfidf_vects)\n",
    "from collections import Counter\n",
    "Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters containing words with maximum strength\n",
    "top_words = 7\n",
    "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for cluster_num in range(6):\n",
    "    key_features = [names[i] for i in centroids[cluster_num, :top_words]]\n",
    "    print('Cluster '+str(cluster_num+1))\n",
    "    print('Top Words:', key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_center=model.cluster_centers_\n",
    "cluster_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[]\n",
    "for i in df['Reviews']:\n",
    "    reviews.append(str(i).split())\n",
    "import gensim\n",
    "w2v_model=gensim.models.Word2Vec(reviews, size=100, workers=4)\n",
    "\n",
    "import numpy as np\n",
    "vectors = []\n",
    "for i in reviews:\n",
    "    vector = np.zeros(100)\n",
    "    count = 0\n",
    "    for word in i:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            vector += vec\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    vector /= count\n",
    "    vectors.append(vector)  \n",
    "vectors = np.array(vectors)\n",
    "vectors = np.nan_to_num(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "minPts = 2 * 100\n",
    "# Lower bound function\n",
    "def lower_bound(nums, target): \n",
    "    l, r = 0, len(nums) - 1\n",
    "    # Binary searching\n",
    "    while l <= r:\n",
    "        mid = int(l + (r - l) / 2)\n",
    "        if nums[mid] >= target:\n",
    "            r = mid - 1\n",
    "        else:\n",
    "            l = mid + 1\n",
    "    return l\n",
    "\n",
    "def compute200thnearestneighbour(x, data): \n",
    "    dists = []\n",
    "    for val in data:\n",
    "      # computing distances\n",
    "        dist = np.sum((x - val) **2 ) \n",
    "        if(len(dists) == 200 and dists[199] > dist): \n",
    "            l = int(lower_bound(dists, dist)) \n",
    "            if l < 200 and l >= 0 and dists[l] > dist:\n",
    "                dists[l] = dist\n",
    "        else:\n",
    "            dists.append(dist)\n",
    "            dists.sort()\n",
    "\n",
    "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
    "    return dists[199]\n",
    "\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
    "twohundrethneigh = []\n",
    "for val in vectors[:1000]:\n",
    "    twohundrethneigh.append( compute200thnearestneighbour(val, vectors[:1000]) )\n",
    "twohundrethneigh.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for the Elbow Method :\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
    "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_dbs = DBSCAN(eps = 5, min_samples = minPts)\n",
    "model_dbs.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbs = df\n",
    "df_dbs[\"DBS Cluster Label\"] = model_dbs.labels_\n",
    "df_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster import hierarchy\n",
    "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
    "plt.axhline(y=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  #took n=3 from dendrogram curve \n",
    "Agg=cluster.fit_predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG-W2V Clus Label'] = cluster.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df = df # Give the labels and group to count the number of data in each clusters.\n",
    "hier_df[\"Hierarchial Cluster Labels\"] = cluster.labels_\n",
    "hier_df.groupby([\"Hierarchial Cluster Labels\"])[\"Reviews\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write you answer here. (No code needed)\n",
    "\n",
    "An unsupervised learning method called K-means clustering brings unlabeled data together based on similarities. The process is iterative and starts with figuring out K. The distance between the data points and the clusters centroids serves as the basis for K-means clustering. fastest of the three techniques able to manage a lot of data Noise and outliers can have a significant impact. Clusters of various sizes can be created by deciding on the number of clusters early on.\n",
    "Density-based spatial grouping of noise-affected applications is referred to as DBSCAN. This type of clustering has the ability to identify clusters with outliers in addition to clusters with randomly organized data. They focus on density, therefore separating high-density regions from low-density areas is their main objective. When dealing with large data sets, K-means clustering performs better than DBSCAN clustering. Utilizing DBSCAN, density-based clustering is carried out. slower than the KMeans approach unable to effectively manage vast amounts of data Noise and outliers can have a significant impact. It is possible to generate clusters of various sizes without having to specify the number of clusters in advance.\n",
    "In hierarchical clustering, data are categorized at several levels of hierarchy. All of the data points are initially provided to the appropriate cluster. Then, the two closest clusters are combined to form one cluster. Up until there is just one cluster left, this process is repeated. As the name implies, hierarchical clustering includes layering clusters. slower than the Kmeans approach It can be more expensive to grow and slower for huge amounts of data. Clusters of the same size are typically produced without first specifying the number of clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
